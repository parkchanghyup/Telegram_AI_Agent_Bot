import os
import logging
import asyncio
import sys
import json
import time
from dotenv import load_dotenv
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
# from agents import Agent, Runner
from agents.mcp import MCPServerStdio
from agents import Agent, Runner, OpenAIChatCompletionsModel, AsyncOpenAI, OpenAIChatCompletionsModel, function_tool



load_dotenv()

logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)

# Ensure file-based logging
os.makedirs('logs', exist_ok=True)
_root_logger = logging.getLogger()
if not any(isinstance(h, logging.FileHandler) for h in _root_logger.handlers):
    _file_handler = logging.FileHandler('logs/bot.log', encoding='utf-8')
    _file_handler.setLevel(logging.INFO)
    _file_handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))
    _root_logger.addHandler(_file_handler)

BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# Instruction prompt ì„¤ì • íŒŒì¼ ê²½ë¡œ ë° ìƒìˆ˜ ë¡œë”©
PROMPT_PATH = os.path.join(os.path.dirname(__file__), "prompt.txt")
try:
    with open(PROMPT_PATH, "r", encoding="utf-8") as f:
        INSTRUCTIONS = f.read().strip()
except FileNotFoundError as exc:
    raise FileNotFoundError("prompt.txt íŒŒì¼ì´ telegram_mcp_bot ë””ë ‰í„°ë¦¬ì— ì—†ìŠµë‹ˆë‹¤.") from exc

if not BOT_TOKEN:
    raise ValueError("TELEGRAM_BOT_TOKEN í™˜ê²½ë³€ìˆ˜ë¥¼ .env íŒŒì¼ì— ì„¤ì •í•´ì£¼ì„¸ìš”.")
if not OPENAI_API_KEY:
    raise ValueError("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ .env íŒŒì¼ì— ì„¤ì •í•´ì£¼ì„¸ìš”.")


mcp_agent = None
mcp_servers = []
mcp_server_map = {}

def _truncate_for_log(text: str, length: int = 200) -> str:
    if text is None:
        return ''
    text = str(text)
    return text if len(text) <= length else text[:length] + 'â€¦'

async def setup_agent_and_servers():
    """MCP ì„œë²„ì™€ AI ì—ì´ì „íŠ¸ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."""
    global mcp_agent, mcp_servers
    
    with open('mcp_config.json', 'r', encoding='utf-8') as f:
        config = json.load(f)

    for server_name, server_config in config.get('mcpServers', {}).items():
        logging.info(f"MCP ì„œë²„ ì¤€ë¹„: name={server_name}, command={server_config.get('command')}, args={server_config.get('args', [])}")
        server = MCPServerStdio(
            params={
                "command": server_config.get("command"),
                "args": server_config.get("args", [])
            },
            cache_tools_list=True
        )
        await server.connect()
        logging.info(f"MCP ì„œë²„ ì—°ê²° ì„±ê³µ: name={server_name}")
        mcp_servers.append(server)
        mcp_server_map[server_name] = server

    model = OpenAIChatCompletionsModel(
        model="conandoyle247/jan-nano-4b-gguf",
        openai_client=AsyncOpenAI(base_url="http://localhost:11434/v1")
    )


    # ì—ì´ì „íŠ¸ ë¶„ë¦¬: ë‹¨ìˆœ Q&A ì—ì´ì „íŠ¸ì™€ ë„¤ì´ë²„ ê²€ìƒ‰ ì—ì´ì „íŠ¸
    qa_agent = Agent(
        name="QnA Agent",
        instructions=INSTRUCTIONS+'/no_think',
        model=model
    )

    naver_instructions = (
        "You are a news search specialist. Use the MCP tool to search latest Naver news.\n"
        "- Prefer concise bullet summaries with title, brief gist, and link.\n"
        "- If the query is not about news or search, do not answer; rely on triage."
        "- answer in Korean"
    )
    # íŠ¹ì • MCP ì„œë²„(ì˜ˆ: 'naver-search')ë§Œ ê²€ìƒ‰ ì—ì´ì „íŠ¸ì— ì—°ê²°
    naver_server = mcp_server_map.get('naver-search')
    naver_agent = Agent(
        name="Naver Search Agent",
        instructions=naver_instructions,
        model=model,
        mcp_servers=[naver_server] if naver_server else []
    )

    # íŠ¸ë¦¬ì•„ì§€ ì—ì´ì „íŠ¸: ë‰´ìŠ¤/ê²€ìƒ‰ ê´€ë ¨ ìš”ì²­ì€ ë„¤ì´ë²„ ê²€ìƒ‰ ì—ì´ì „íŠ¸ë¡œ, ê·¸ ì™¸ëŠ” QnAë¡œ ì „ë‹¬
    mcp_agent = Agent(
        name="Triage Agent",
        instructions=(
            "If the user asks for news, headlines, today's updates, or mentions ê²€ìƒ‰/ë‰´ìŠ¤/ë„¤ì´ë²„/ê¸°ì‚¬/ì‹¤ì‹œê°„, "
            "hand it off to the Naver Search Agent. Otherwise, hand it off to the QnA Agent. "
            "If unclear, prefer QnA Agent."
        ),
        handoffs=[naver_agent, qa_agent]
    )
    logging.info("AI ì—ì´ì „íŠ¸ ë° MCP ì„œë²„ê°€ ì„±ê³µì ìœ¼ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """ë´‡ ì‹œì‘ ëª…ë ¹ì–´ í•¸ë“¤ëŸ¬"""
    welcome_message = """
ğŸ¤– ì•ˆë…•í•˜ì„¸ìš”! AI ì—ì´ì „íŠ¸ ë´‡ì…ë‹ˆë‹¤.
ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”. ìµœì‹  ë‰´ìŠ¤ê°€ ê¶ê¸ˆí•˜ë©´ ê²€ìƒ‰ì„ ìš”ì²­í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.
ì˜ˆ: "ì˜¤ëŠ˜ì˜ ì£¼ìš” ë‰´ìŠ¤ ì•Œë ¤ì¤˜"
"""
    await update.message.reply_text(welcome_message)

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ AI ì—ì´ì „íŠ¸ë¡œ ì²˜ë¦¬í•˜ëŠ” í•¸ë“¤ëŸ¬"""
    user_message = update.message.text
    logging.info(f"ì‚¬ìš©ìë¡œë¶€í„° ë©”ì‹œì§€ ë°›ìŒ: {user_message}")

    if not mcp_agent:
        await update.message.reply_text("ì£„ì†¡í•©ë‹ˆë‹¤. ì—ì´ì „íŠ¸ê°€ ì•„ì§ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return

    processing_message = await update.message.reply_text("ğŸ”„ ìƒê° ì¤‘...")

    try:
        start_time = time.perf_counter()
        result = await Runner.run(mcp_agent, input=user_message)
        duration_ms = (time.perf_counter() - start_time) * 1000.0
        response_text = str(result.final_output)

        # Log concise Q&A record
        logging.info(
            "QnA ì²˜ë¦¬ ì™„ë£Œ: duration_ms=%.1f, user='%s', response='%s'",
            duration_ms,
            _truncate_for_log(user_message),
            _truncate_for_log(response_text)
        )

        await processing_message.delete()
        await update.message.reply_text(response_text)

    except Exception as e:
        logging.error(f"ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        await processing_message.delete()
        await update.message.reply_text(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

async def shutdown_servers(app):
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œ ì‹œ MCP ì„œë²„ ì—°ê²°ì„ ì¢…ë£Œí•©ë‹ˆë‹¤."""
    global mcp_servers
    logging.info("MCP ì„œë²„ ì—°ê²°ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    for server in mcp_servers:
        await server.disconnect()
    logging.info("MCP ì„œë²„ ì—°ê²°ì´ ëª¨ë‘ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

def main() -> None:
    """ë´‡ ì‹¤í–‰ ë©”ì¸ í•¨ìˆ˜"""
    loop = asyncio.get_event_loop()
    
    try:
        loop.run_until_complete(setup_agent_and_servers())
    except Exception as e:
        logging.error(f"ì´ˆê¸° ì„¤ì • ì‹¤íŒ¨: {e}")
        return

    application = Application.builder().token(BOT_TOKEN).post_shutdown(shutdown_servers).build()

    application.add_handler(CommandHandler("start", start))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    logging.info("ğŸ¤– AI ì—ì´ì „íŠ¸ í…”ë ˆê·¸ë¨ ë´‡ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤...")
    application.run_polling()

if __name__ == '__main__':
    main()
